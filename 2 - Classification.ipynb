{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aa5cefc",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "# 2 - Classification\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "In this example, we will build a flower classifier of 3 classes:\n",
    "* Setosa\n",
    "* Versicolor\n",
    "* Virginica\n",
    "\n",
    "Based on 4 numerical variables:\n",
    "* Sepal length\n",
    "* Sepal width\n",
    "* Petal length\n",
    "* Petal width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fd9ced",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## 1.0 - Importing Modules\n",
    "\n",
    "---\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee879085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from six.moves import urllib\n",
    "\n",
    "import tensorflow.compat.v2.feature_column as fc\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd01219",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## 2.0 - Dataset\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "The dataset is obtained through the submodule `keras`, responsible for deep learning stuff, from `tensorflow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aedf272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default the CSV file header is messy. Let's use our own header\n",
    "COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']  \n",
    "# The CSV encodes species with 0, 1 and 2. Use this array to decode\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8624498d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris training file location C:\\Users\\Acer\\.keras\\datasets\\iris_training.csv\n",
      "Iris test file location C:\\Users\\Acer\\.keras\\datasets\\iris_test.csv\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset from online source into our local machine\n",
    "train_path = tf.keras.utils.get_file('iris_training.csv', 'https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv')\n",
    "test_path = tf.keras.utils.get_file('iris_test.csv', 'https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv')\n",
    "\n",
    "clear_output()\n",
    "\n",
    "print(\"Iris training file location \" + train_path)\n",
    "print(\"Iris test file location \" + test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "477c274a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv into pandas dataframe\n",
    "train_data = pd.read_csv(train_path, names=COLUMN_NAMES, header=0)\n",
    "test_data = pd.read_csv(test_path, names=COLUMN_NAMES, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5f17e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the labels (Species) from the dataframe itself which consist of features (columns)\n",
    "train_y = train_data.pop('Species')\n",
    "test_y = test_data.pop('Species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d702ab3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
       "0          6.4         2.8          5.6         2.2\n",
       "1          5.0         2.3          3.3         1.0\n",
       "2          4.9         2.5          4.5         1.7\n",
       "3          4.9         3.1          1.5         0.1\n",
       "4          5.7         3.8          1.7         0.3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see our data\n",
    "print(train_data.shape)       # 120 rows, 4 columns\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1daa82c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    1\n",
       "2    2\n",
       "3    0\n",
       "4    0\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels. Note that they are integers (0,1,2), and we need to map them into meaningful classes \n",
    "# like Versicolor later\n",
    "train_y.head()        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7522bef",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## 3.0 - Input Function\n",
    "\n",
    "---\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f64e2718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of like last input function where we specify the epochs and shuffle, this time they are both triggered by a boolean parameter\n",
    "# isTraining. If isTraining is true, then do shuffle and have multiple epochs\n",
    "# Also, now input function no need to have the input function to return another function\n",
    "def input_function( features, labels, isTraining=True, batch_size=256):\n",
    "  # Convert input into datasets\n",
    "  dataset = tf.data.Dataset.from_tensor_slices( (dict(features), labels) )\n",
    "\n",
    "  # If in training mode, shuffle and epochs\n",
    "  if isTraining:\n",
    "    dataset = dataset.shuffle(1000).repeat()\n",
    "\n",
    "  return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac6bd74",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## 4.0 - Feature Columns\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "We have 4 numeric columns\n",
    "* Sepal Length\n",
    "* Sepal Width\n",
    "* Petal Length\n",
    "* Petal Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d45217f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SepalLength\n",
      "SepalWidth\n",
      "PetalLength\n",
      "PetalWidth\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We simply has 4 features, which are all in unit length, so they are numeric column, and not categorical\n",
    "feature_columns = []\n",
    "\n",
    "for key in train_data.keys():\n",
    "  print(key)\n",
    "  feature_columns.append(tf.feature_column.numeric_column(key) )\n",
    "\n",
    "print()\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8d1efd",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## 5.0 - Building The Model\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "* There are various classification models, but some of the well known ones are:\n",
    "  * `DNNClassifier` (Deep neural Network)\n",
    "  * `LinearClassifier` - Works like linear regression except it classifies\n",
    "\n",
    "\n",
    "* In this case we chose `DNNClassifier` because the features (sepal length etc...) might not just be related to labels (Versicolor, Virginica...) via linear relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e844105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember that tf.estimator has a ton of pre made models\n",
    "\n",
    "# DNNClassifiers need to have a hidden_units specified. It is a building architecture\n",
    "# of the DNN. Remember that the neural network has layers:\n",
    "#       Input layers - Hidden layers - Output layers\n",
    "classifier = tf.estimator.DNNClassifier( \n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=[30,10],\n",
    "    n_classes=3 )         \n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21f0e1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\My Desktop\\Programming\\Projects\\MachineLearning\\venv\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:235: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From D:\\My Desktop\\Programming\\Projects\\MachineLearning\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\adagrad.py:87: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\Acer\\AppData\\Local\\Temp\\tmpmdvo7o08\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 2.3024757, step = 0\n",
      "INFO:tensorflow:global_step/sec: 559.49\n",
      "INFO:tensorflow:loss = 1.564131, step = 100 (0.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 788.829\n",
      "INFO:tensorflow:loss = 1.2945862, step = 200 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 809.253\n",
      "INFO:tensorflow:loss = 1.1389867, step = 300 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 818.66\n",
      "INFO:tensorflow:loss = 1.0489466, step = 400 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 807.91\n",
      "INFO:tensorflow:loss = 0.9799361, step = 500 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 799.71\n",
      "INFO:tensorflow:loss = 0.9265241, step = 600 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 827.939\n",
      "INFO:tensorflow:loss = 0.89668536, step = 700 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 811.23\n",
      "INFO:tensorflow:loss = 0.85830355, step = 800 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 749.561\n",
      "INFO:tensorflow:loss = 0.8359062, step = 900 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 739.099\n",
      "INFO:tensorflow:loss = 0.81370205, step = 1000 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 740.053\n",
      "INFO:tensorflow:loss = 0.7875238, step = 1100 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 785.072\n",
      "INFO:tensorflow:loss = 0.7786757, step = 1200 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 753.52\n",
      "INFO:tensorflow:loss = 0.7606088, step = 1300 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 824.383\n",
      "INFO:tensorflow:loss = 0.74534786, step = 1400 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 864.263\n",
      "INFO:tensorflow:loss = 0.7296319, step = 1500 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 848.981\n",
      "INFO:tensorflow:loss = 0.71229446, step = 1600 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 809.875\n",
      "INFO:tensorflow:loss = 0.69195753, step = 1700 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 646.174\n",
      "INFO:tensorflow:loss = 0.6911508, step = 1800 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 758.569\n",
      "INFO:tensorflow:loss = 0.66912353, step = 1900 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 740.959\n",
      "INFO:tensorflow:loss = 0.6591095, step = 2000 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 810.779\n",
      "INFO:tensorflow:loss = 0.65602034, step = 2100 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.555\n",
      "INFO:tensorflow:loss = 0.6389154, step = 2200 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 820.85\n",
      "INFO:tensorflow:loss = 0.62981826, step = 2300 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 807.229\n",
      "INFO:tensorflow:loss = 0.6311153, step = 2400 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 789.339\n",
      "INFO:tensorflow:loss = 0.6234903, step = 2500 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 753.563\n",
      "INFO:tensorflow:loss = 0.62084424, step = 2600 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 754.484\n",
      "INFO:tensorflow:loss = 0.60649467, step = 2700 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.512\n",
      "INFO:tensorflow:loss = 0.60468936, step = 2800 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 809.882\n",
      "INFO:tensorflow:loss = 0.5827029, step = 2900 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.472\n",
      "INFO:tensorflow:loss = 0.58788484, step = 3000 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 853.113\n",
      "INFO:tensorflow:loss = 0.5760989, step = 3100 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 848.126\n",
      "INFO:tensorflow:loss = 0.5689008, step = 3200 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 823.685\n",
      "INFO:tensorflow:loss = 0.5729756, step = 3300 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 808.817\n",
      "INFO:tensorflow:loss = 0.57021344, step = 3400 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 805.39\n",
      "INFO:tensorflow:loss = 0.55083334, step = 3500 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 822.91\n",
      "INFO:tensorflow:loss = 0.55263054, step = 3600 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 730.513\n",
      "INFO:tensorflow:loss = 0.54151005, step = 3700 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 696.427\n",
      "INFO:tensorflow:loss = 0.54501826, step = 3800 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 807.439\n",
      "INFO:tensorflow:loss = 0.5377931, step = 3900 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 821.684\n",
      "INFO:tensorflow:loss = 0.5394502, step = 4000 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 785.384\n",
      "INFO:tensorflow:loss = 0.53169537, step = 4100 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 793.011\n",
      "INFO:tensorflow:loss = 0.5221797, step = 4200 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 701.808\n",
      "INFO:tensorflow:loss = 0.52430844, step = 4300 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 821.104\n",
      "INFO:tensorflow:loss = 0.5133349, step = 4400 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 739.8\n",
      "INFO:tensorflow:loss = 0.51388323, step = 4500 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 770.846\n",
      "INFO:tensorflow:loss = 0.51513773, step = 4600 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 803.757\n",
      "INFO:tensorflow:loss = 0.5071734, step = 4700 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 749.837\n",
      "INFO:tensorflow:loss = 0.49943444, step = 4800 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 774.946\n",
      "INFO:tensorflow:loss = 0.4955694, step = 4900 (0.128 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\Acer\\AppData\\Local\\Temp\\tmpmdvo7o08\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.49490744.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x29dfd5918b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model. Remember that input function parameter need to have a function which has\n",
    "# no parameter, but inside it must know about the training data and labels. So use lambda\n",
    "# as outer function for it\n",
    "#\n",
    "# \"steps\" is similar to epochs, but it means to go though precisely 5000 items instead of like\n",
    "# iterate the datasets N times.\n",
    "classifier.train(\n",
    "    input_fn = lambda: input_function(train_data, train_y),\n",
    "    steps = 5000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa7459a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## 6.0 - Predicting User Inputs\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "Our model is done training. Let's obtain user input and predict the class of flower!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dbf6dc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the numeric value as prompted:\n",
      "SepalLength: 2.4\n",
      "SepalWidth: 2.6\n",
      "PetalLength: 6.5\n",
      "PetalWidth: 6.3\n",
      "{'SepalLength': [2.4], 'SepalWidth': [2.6], 'PetalLength': [6.5], 'PetalWidth': [6.3]}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Acer\\AppData\\Local\\Temp\\tmpmdvo7o08\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "# Remember, even though user input is only size 1 (unlike test datasets), it also requires an input function of its own\n",
    "# We can do that!\n",
    "def user_input_function(features, batch_size=256):\n",
    "  return tf.data.Dataset.from_tensor_slices( dict(features) ).batch(batch_size)\n",
    "features = COLUMN_NAMES[:4]\n",
    "user_input = {}\n",
    "\n",
    "\n",
    "print(\"Please enter the numeric value as prompted:\")\n",
    "for feature in features:\n",
    "  user_input[feature] = [float( input(feature + \": \") )]       # Array of size 1. Only 1 item to predict\n",
    "\n",
    "# The user input obtained and will be predicted\n",
    "print(user_input, end='\\n\\n')\n",
    "\n",
    "# Remember: It returns a generator. We use list()\n",
    "predicted_res = list( classifier.predict(input_fn=lambda: user_input_function(user_input) ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "399e1cbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: Virginica with certainty of 91.11234545707703%\n"
     ]
    }
   ],
   "source": [
    "# The prediction is still in integer, map it to meaningful class name like Versicolor\n",
    "predicted_id = predicted_res[0]['class_ids'][0]\n",
    "predicted_flower = SPECIES[predicted_id]\n",
    "predicted_prob = predicted_res[0]['probabilities'][predicted_id]\n",
    "\n",
    "print(f'Predicted: {predicted_flower} with certainty of {predicted_prob * 100}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
