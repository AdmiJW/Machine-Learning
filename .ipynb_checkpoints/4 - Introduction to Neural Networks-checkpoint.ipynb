{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1be802ff",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "# 4 - Introduction to Neural Networks\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "Neural networks consist of an __input layer__, one or more __hidden layers__ and __output layer__.\n",
    "\n",
    "Usually, the amount of tensors in input layer matches exactly how many input you'll need. Say an image of size 10x10, then you would need 100 input tensors for that, one for each pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528ef916",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## 1.0 - Importing Modules\n",
    "\n",
    "---\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dda3182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Machine learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225a9210",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## 2.0 - Datasets\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "For this tutorial, the dataset that will be used is the MNIST Fashion Dataset, which is included in keras. It includes 60000 fashion item images sized 28 x 28 for training, and 10000 images for validation / testing.\n",
    "\n",
    "Note that those images come in the form of `numpy.ndarray`, of size (28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35a983ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 5s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Download and load the datasets\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d16cef82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 60000 training data\n",
      "There are 10000 testing data\n",
      "The images are (28, 28) in size \n",
      "The pixel value ranges from 0 to 255\n",
      "The label's unique values are {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, meaning 10 classes to classify \n"
     ]
    }
   ],
   "source": [
    "# General information: How many images are there? What is the size of images?\n",
    "print( f\"There are { len(train_images) } training data\" )\n",
    "print( f\"There are { len(test_images) } testing data\")\n",
    "print( f\"The images are { train_images[0].shape } in size \")\n",
    "print( f\"The pixel value ranges from { train_images[0].min() } to { train_images[0].max() }\")\n",
    "print( f\"The label's unique values are { set(test_labels) }, meaning { len(set(test_labels) ) } classes to classify \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0641ccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Classes by index doesn't make sense. Let's create an array that describes what those classes are actually\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9e9caa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 0 to 59999 to see images: 312\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a Coat\n"
     ]
    }
   ],
   "source": [
    "# Let's peek at some of the images\n",
    "# We'll let user to pick the image.\n",
    "plt.figure()\n",
    "\n",
    "id = 0\n",
    "while True:\n",
    "  id = input(\"Enter 0 to 59999 to see images: \")\n",
    "\n",
    "  if id.isdigit() and 0 <= int(id) < 60000:\n",
    "    id = int(id)\n",
    "    break\n",
    "  print(\"Invalid Number! Must be between 0 to 59999\")\n",
    "\n",
    "\n",
    "\n",
    "plt.imshow( train_images[id] )\n",
    "\n",
    "plt.show()\n",
    "print(\"It is a\", class_names[ train_labels[id] ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9636317",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## 3.0 - Data Preprocessing\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "Data Preprocessing is important so that we don't throw in junk datas into our machine learning model. In this case the data is clean, but we can do a little optimization to make it easier to train.\n",
    "\n",
    "The Pixel values are between 0 to 255. Preferrably, we want it to only be between 0 to 1 because that is the nature value of the machine learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3983b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ef51b9",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## 4.0 - Building The Model\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "The model that we will use here is, of course, Neural networks. The module responsible for this is the keras submodule in tensorflow.\n",
    "\n",
    "\n",
    "In this case, the whole model is based off keras.Sequential. Sequential means that one layer follows another, like input layer > hidden layers > output layers.\n",
    "\n",
    "\n",
    "After building the model, we need to compile the model, specifying the optimizer function, loss function as well as the metrics we are going to obtain.\n",
    "\n",
    "\n",
    "In this example, the hidden layers we choose is simply __Dense Convolutional Layer__, which means all nodes/tensors are connected to __all__ the nodes in the next layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db29e6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model = keras.Sequential([         # Takes in an array of layers\n",
    "  keras.layers.Flatten( input_shape=(28,28) ),    # Flattens the input into one dimensional. In our case 28x28 image is flattened to 784 input tensors                                         \n",
    "  keras.layers.Dense(128, activation='relu'),     # Dense layer with 128 tensors. Activation function is Rectified Linear Unit\n",
    "  keras.layers.Dense(10, activation='softmax')    # Dense layer with 10 tensors. Makes sense because we are having 10 classes to classify here\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39dcbdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the layers are set, we have to compile our model before actually using it\n",
    "classification_model.compile(\n",
    "    optimizer='adam',                             # An optimizer function that uses gradient descent\n",
    "    loss='sparse_categorical_crossentropy',       # Loss function\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531fcc9b",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## 5.0 - Train The Model\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "Fortunately, `keras` automatically handles the input function for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03e13c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1875/1875 [==============================] - 2s 991us/step - loss: 0.4913 - accuracy: 0.8262\n",
      "Epoch 2/8\n",
      "1875/1875 [==============================] - 2s 904us/step - loss: 0.3715 - accuracy: 0.8656\n",
      "Epoch 3/8\n",
      "1875/1875 [==============================] - 2s 929us/step - loss: 0.3352 - accuracy: 0.8781\n",
      "Epoch 4/8\n",
      "1875/1875 [==============================] - 2s 893us/step - loss: 0.3099 - accuracy: 0.8869\n",
      "Epoch 5/8\n",
      "1875/1875 [==============================] - 2s 917us/step - loss: 0.2911 - accuracy: 0.8927\n",
      "Epoch 6/8\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2778 - accuracy: 0.8968\n",
      "Epoch 7/8\n",
      "1875/1875 [==============================] - 2s 955us/step - loss: 0.2657 - accuracy: 0.9018\n",
      "Epoch 8/8\n",
      "1875/1875 [==============================] - 2s 895us/step - loss: 0.2555 - accuracy: 0.9041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2ba56c480d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Give training images, training labels and number of epochs\n",
    "classification_model.fit( train_images, train_labels, epochs=8 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21b0d1d",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## 6.0 - Evaluating our Model\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "From the epochs output above, we see the accuracy falls around 80%. How do we know if it is not overfitted? Use test data which the model never seen before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "937e5b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 695us/step - loss: 0.3461 - accuracy: 0.8803\n",
      "The test is done with accuracy: 0.880299985408783\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = classification_model.evaluate(test_images, test_labels, verbose=True)\n",
    "\n",
    "print( f\"The test is done with accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae45ca0",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## 7.0 - Making Predictions\n",
    "\n",
    "---\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19d9af67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.6749235e-07, 4.8150534e-10, 1.3643842e-07, 3.7579618e-08,\n",
       "       6.6462185e-08, 3.1779642e-04, 1.5869067e-06, 3.2580860e-02,\n",
       "       8.1223197e-07, 9.6709812e-01], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can just use our model to start making predictions. It will return all the output values for all 10 output tensors\n",
    "# The output shall be array of size 10, each one representing the probability that the image is in corresponding classes \n",
    "predictions = classification_model.predict( test_images )\n",
    "\n",
    "predictions[0]\n",
    "# The class predicted will have the closest value to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca68d9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instead of looking at all the probabilities, let's take out the maximum value via numpy.argmax()\n",
    "# it will return the index of largest value\n",
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df4e4720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the image to predict (0-9999): 123\n",
      "The image to predict:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: Ankle Boot\n",
      "The correct answer is: Ankle Boot \n"
     ]
    }
   ],
   "source": [
    "# Therefore let's get user input to select what they want to predict!\n",
    "\n",
    "\n",
    "id = 0\n",
    "while True:\n",
    "  id = input(\"Enter the image to predict (0-9999): \")\n",
    "\n",
    "  if id.isdigit() and 0 <= int(id) < 10000:\n",
    "    id = int(id)\n",
    "    break\n",
    "  print(\"Invalid id! Retry\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"The image to predict:\")\n",
    "plt.figure()\n",
    "plt.imshow( test_images[id] )\n",
    "plt.show()\n",
    "\n",
    "predictions = classification_model.predict( np.array([test_images[id]]) )\n",
    "\n",
    "print( f\"The predicted class is: { class_names[ np.argmax(predictions[0] ) ] }\" )\n",
    "print( f\"The correct answer is: { class_names[ test_labels[id] ] } \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9eeea8",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## 8.0 - Saving Model and Loading Model\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "If our dataset is more complex, training the model certainly may take minutes or even hours! With our model trained, we don't want to train it again once we restarted our application! This is where we shall save our model into file format\n",
    "\n",
    "\n",
    "In this example where our model is of type `tensorflow.python.keras.engine.sequential.Sequential`, simply call the `save()` function. Documentation [__HERE__](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#save)\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "When we want to load up our model, use `load_model()` function from `keras.models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29884616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving our model\n",
    "# The function signature is:\n",
    "# save(\n",
    "#    filepath, overwrite=True, include_optimizer=True, save_format=None,\n",
    "#    signatures=None, options=None, save_traces=True\n",
    "# )\n",
    "\n",
    "FILEPATH = 'trained_models/4_Introduction_To_Neural_Networks.h5'\n",
    "\n",
    "classification_model.save( FILEPATH )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7777d6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading our model\n",
    "loaded_model = tf.keras.models.load_model( FILEPATH )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c6308b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.6749235e-07, 4.8150534e-10, 1.3643842e-07, 3.7579618e-08,\n",
       "       6.6462185e-08, 3.1779642e-04, 1.5869067e-06, 3.2580860e-02,\n",
       "       8.1223197e-07, 9.6709812e-01], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To prove it is the exact same model, let's test if the values are of the same:\n",
    "predictions = loaded_model.predict( test_images )\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05519ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
